{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd99bc65-43cf-4b96-a851-f13e090add21",
   "metadata": {},
   "source": [
    "# Atelier 2: Introduction à l'IA Agentique et au Model Context Protocol (MCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ed0e0-ffad-4d2c-a8b1-b00bb0fe664f",
   "metadata": {},
   "source": [
    "## Table des matières:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8a6fd-32a6-483e-83ce-505115b5ba61",
   "metadata": {},
   "source": [
    "1. Comprendre l'IA Agentique\n",
    "2. Introduction au Model Context Protocol (MCP)\n",
    "3. Premier pas avec le MCP\n",
    "4. Création d'un serveur MCP simple avec Flask\n",
    "5. Création d'un client MCP\n",
    "6. Exercice\n",
    "7. Intégration avec un LLM\n",
    "\n",
    "---\n",
    "\n",
    "Bienvenue à cet atelier sur l'IA Agentique et les MCP! Aujourd'hui, nous allons explorer l'IA Agentique et créer nos propres servers MCP.\n",
    "\n",
    "**Objectifs de l'atelier:**\n",
    "1. Comprendre ce qu'est l'IA agentique\n",
    "2. Explorer le Model Context Protocol (MCP)\n",
    "3. Créer un serveur MCP simple\n",
    "4. Développer un agent IA basique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660350f-e250-4f3f-a301-8108e87282d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b1d62-3330-4524-957c-f294a239f6db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Comprendre l'IA Agentique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e9c9a-9474-42dc-b4b1-c2cd6b852d98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Qu'est-ce qu'un agent IA?\n",
    "\n",
    "Un **agent IA** est un système qui peut:\n",
    "- Percevoir son environnement\n",
    "- Prendre des décisions autonomes\n",
    "- Agir pour atteindre des objectifs spécifiques\n",
    "- Utiliser des outils externes\n",
    "\n",
    "Contrairement à un simple modèle de langage qui génère du texte, un agent IA peut interagir avec le monde extérieur et exécuter des actions concrètes.\n",
    "\n",
    "### Composants d'un agent IA\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://lh7-rt.googleusercontent.com/docsz/AD_4nXcM5IG8AX4rfhy8xP49NnRDK1X3KYfRpFtoU9XUKDXRRPDD3JhjMiJC12wk1r2D2aEhUZwvvW42WB4fn8cm5dgqlVIiSzB95fYO2GPATVK17Yk5DpU7Npzj1uLwoXLI4TVOFaDQWQ?key=UertKaKWfse9WlKbf6sBHwn1\" alt=\"Architecture Agent IA\" width=\"600\"/>\n",
    "    <p><em>Source: <a href=\"https://writesonic.com/blog/what-is-an-ai-agent\">writesonic.com</a></em></p>\n",
    "</div>\n",
    "\n",
    "1. **Modèle de langage (LLM/SLM)**: Le \"cerveau\" qui comprend les requêtes et génère des réponses\n",
    "2. **Système de planification**: Décompose les tâches complexes en étapes simples\n",
    "3. **Interface avec des outils**: Permet d'interagir avec des API, bases de données, MCP, etc.\n",
    "4. **Mémoire**: Stocke les conversations et le contexte\n",
    "\n",
    "### Exemples d'applications des agents IA\n",
    "\n",
    "- Assistant personnel qui peut envoyer des emails, planifier des réunions\n",
    "- Agent de recherche qui collecte et synthétise des informations\n",
    "- Assistant de programmation qui peut écrire et tester du code\n",
    "- Agent d'automatisation qui exécute des workflows complexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc485b88-e08d-4958-9c7d-0df755bd91ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Introduction au Model Context Protocol (MCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55bac90-3c68-4495-9b7b-a6a3be292629",
   "metadata": {},
   "source": [
    "### Qu'est-ce que le MCP?\n",
    "\n",
    "Le **Model Context Protocol (MCP)** est un standard qui permet aux modèles de langage d'interagir avec des outils externes de manière structurée et sécurisée.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/0*ydhvFVVoKyOfEHMi.png\" alt=\"Architecture MCP\" width=\"600\"/>\n",
    "    <p><em>Source: <a href=\"https://generativeai.pub/learn-mcp-servers-with-python-an-essential-guide-to-model-context-protocol-servers-97984f37eceb\">generativeai.pub</a></em></p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "### Pourquoi utiliser le MCP?\n",
    "\n",
    "- **Standardisation**: Interface commune pour tous les outils\n",
    "- **Sécurité**: Contrôle précis des capacités du modèle\n",
    "- **Extensibilité**: Facile d'ajouter de nouveaux outils\n",
    "- **Transparence**: L'utilisateur peut voir quels outils sont utilisés\n",
    "\n",
    "### Comment fonctionne le MCP?\n",
    "\n",
    "1. Le modèle reçoit une description des outils disponibles\n",
    "2. Lorsqu'il a besoin d'utiliser un outil, il génère une requête structurée\n",
    "3. Le serveur MCP exécute l'outil et renvoie le résultat\n",
    "4. Le modèle intègre ce résultat dans sa réponse\n",
    "\n",
    "### Structure d'un outil MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f322127-3ff0-4e1f-b7bb-1336bc632f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de définition d'outil MCP\n",
    "tool_example = {\n",
    "    \"name\": \"calculator\",\n",
    "    \"description\": \"Effectue des calculs mathématiques\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"expression\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"L'expression mathématique à évaluer\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"expression\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Exemple de définition d'outil MCP:\")\n",
    "print(json.dumps(tool_example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece82b2c-b207-4662-a783-1ca4a812d9fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. Premiers pas avec MCP\n",
    "\n",
    "Commençons par définir quelques outils simples que nous pourrons utiliser avec notre modèle de langage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82261a2-0324-4308-b812-e93ce6589078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de nos outils MCP\n",
    "MCP_TOOLS = [\n",
    "    {\n",
    "        \"name\": \"get_current_time\",\n",
    "        \"description\": \"Obtient l'heure et la date actuelles\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"calculate\",\n",
    "        \"description\": \"Effectue un calcul mathématique\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"L'expression mathématique à évaluer\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Nos outils MCP:\")\n",
    "print(json.dumps(MCP_TOOLS, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e944e07-519e-40ba-97b6-2764b453719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implémentation des fonctions d'outils\n",
    "def get_current_time():\n",
    "    \"\"\"Renvoie l'heure et la date actuelles.\"\"\"\n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Évalue une expression mathématique.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Le résultat de {expression} est {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Erreur lors du calcul: {str(e)}\"\n",
    "\n",
    "# Fonction pour simuler l'appel d'un outil MCP\n",
    "def simulate_mcp_call(tool_name, parameters):\n",
    "    \"\"\"Simule l'appel d'un outil MCP.\"\"\"\n",
    "    if tool_name == \"get_current_time\":\n",
    "        return get_current_time()\n",
    "    elif tool_name == \"calculate\":\n",
    "        return calculate(parameters.get(\"expression\", \"\"))\n",
    "    else:\n",
    "        return \"Outil inconnu\"\n",
    "\n",
    "# Exemples d'utilisation\n",
    "print(\"Démonstration d'appels MCP:\")\n",
    "print(f\"get_current_time: {simulate_mcp_call('get_current_time', {})}\")\n",
    "print(f\"calculate: {simulate_mcp_call('calculate', {'expression': '23 * 7 + 15'})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0053ad-0031-4bd2-aa45-55c33168a049",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Création d'un serveur MCP simple avec Flask\n",
    "\n",
    "Pour créer un véritable serveur MCP, nous allons utiliser Flask. Dans un environnement de production, vous exécuteriez ce code dans un fichier séparé, mais ici nous allons l'examiner dans le notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c558d4e-55be-4094-9e9e-117f94581047",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Code du serveur MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9cb58-0d6d-4c5a-8976-a11460cab1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Définition des outils disponibles\n",
    "TOOLS = [\n",
    "    {\n",
    "        \"name\": \"get_current_time\",\n",
    "        \"description\": \"Obtient l'heure et la date actuelles\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"calculate\",\n",
    "        \"description\": \"Effectue un calcul mathématique\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"L'expression mathématique à évaluer\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Obtient la météo pour une ville donnée\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Le nom de la ville\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "@app.route('/tools', methods=['GET'])\n",
    "def get_tools():\n",
    "    return jsonify(TOOLS)\n",
    "\n",
    "@app.route('/run_tool', methods=['POST'])\n",
    "def run_tool():\n",
    "    data = request.json\n",
    "    tool_name = data.get('name')\n",
    "    parameters = data.get('parameters', {})\n",
    "    \n",
    "    if tool_name == \"get_current_time\":\n",
    "        result = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return jsonify({\"result\": result})\n",
    "    \n",
    "    elif tool_name == \"calculate\":\n",
    "        expression = parameters.get('expression')\n",
    "        try:\n",
    "            # Attention: eval peut être dangereux en production\n",
    "            result = eval(expression)\n",
    "            return jsonify({\"result\": f\"Le résultat de {expression} est {result}\"})\n",
    "        except Exception as e:\n",
    "            return jsonify({\"error\": f\"Erreur de calcul: {str(e)}\"}), 400\n",
    "    \n",
    "    elif tool_name == \"get_weather\":\n",
    "        city = parameters.get('city')\n",
    "        # Dans un cas réel, vous utiliseriez une API météo\n",
    "        # Ici, nous simulons une réponse\n",
    "        weather_data = {\n",
    "            \"Paris\": \"21°C, Ensoleillé\",\n",
    "            \"New York\": \"18°C, Nuageux\",\n",
    "            \"Tokyo\": \"25°C, Pluie légère\",\n",
    "            \"London\": \"15°C, Brouillard\"\n",
    "        }\n",
    "        result = weather_data.get(city, f\"Données météo non disponibles pour {city}\")\n",
    "        return jsonify({\"result\": result})\n",
    "    \n",
    "    return jsonify({\"error\": \"Outil non reconnu\"}), 400\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc3dc7-10e3-4f93-842b-cebd77a091d8",
   "metadata": {},
   "source": [
    "Pour exécuter ce serveur, vous devriez sauvegarder ce code dans un fichier `mcp_server.py` et l'exécuter avec `python mcp_server.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc97fea-cfa7-4309-9c1d-799705db6945",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Client MCP pour tester le serveur\n",
    "\n",
    "Maintenant, créons un client simple pour interagir avec notre serveur MCP. Dans un environnement réel, ce client serait intégré à votre modèle de langage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303e054-ec99-44b0-af32-5ae706187ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL du serveur MCP (à adapter selon votre configuration)\n",
    "MCP_SERVER_URL = \"http://localhost:5000\"\n",
    "\n",
    "# 1. Récupérer la liste des outils disponibles\n",
    "def get_available_tools():\n",
    "    response = requests.get(f\"{MCP_SERVER_URL}/tools\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Erreur: {response.status_code}\"\n",
    "\n",
    "# 2. Exécuter un outil\n",
    "def run_tool(tool_name, parameters={}):\n",
    "    data = {\n",
    "        \"name\": tool_name,\n",
    "        \"parameters\": parameters\n",
    "    }\n",
    "    response = requests.post(f\"{MCP_SERVER_URL}/run_tool\", json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Erreur: {response.status_code}\"\n",
    "\n",
    "# Exemples d'utilisation (à exécuter une fois le serveur lancé)\n",
    "def test_mcp_client():\n",
    "    print(\"Outils disponibles:\")\n",
    "    tools = get_available_tools()\n",
    "    print(json.dumps(tools, indent=2))\n",
    "\n",
    "    print(\"\\\\nHeure actuelle:\")\n",
    "    time_result = run_tool(\"get_current_time\")\n",
    "    print(time_result)\n",
    "\n",
    "    print(\"\\\\nCalcul mathématique:\")\n",
    "    calc_result = run_tool(\"calculate\", {\"expression\": \"42 * 3 - 15\"})\n",
    "    print(calc_result)\n",
    "\n",
    "    print(\"\\\\nMétéo à Paris:\")\n",
    "    weather_result = run_tool(\"get_weather\", {\"city\": \"Paris\"})\n",
    "    print(weather_result)\n",
    "\n",
    "# Décommentez pour tester une fois le serveur lancé\n",
    "# test_mcp_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49816ede-bd48-4aef-b786-b1241237845a",
   "metadata": {},
   "source": [
    "**Note**: Pour exécuter ce client, vous devez d'abord lancer le serveur MCP dans un terminal séparé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b573dd9-74d8-40c5-ad67-64d35f6c4084",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6. Exercice: Ajouter un nouvel outil MCP\n",
    "\n",
    "Maintenant, c'est à votre tour! Créez un nouvel outil MCP qui permet de convertir des devises.\n",
    "\n",
    "### Spécifications:\n",
    "- Nom: `convert_currency`\n",
    "- Description: \"Convertit un montant d'une devise à une autre\"\n",
    "- Paramètres:\n",
    "  - `amount`: Le montant à convertir (nombre)\n",
    "  - `from_currency`: La devise source (ex: EUR, USD)\n",
    "  - `to_currency`: La devise cible (ex: EUR, USD)\n",
    "\n",
    "### Taux de conversion à utiliser (simplifiés):\n",
    "- 1 EUR = 1.10 USD\n",
    "- 1 EUR = 0.85 GBP\n",
    "- 1 EUR = 160 JPY\n",
    "- 1 USD = 0.91 EUR\n",
    "- 1 USD = 0.77 GBP\n",
    "- 1 USD = 145 JPY\n",
    "\n",
    "Complétez le code ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7ad9f-b3e3-4ffc-8e5b-6450faef8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice: Ajouter un nouvel outil MCP pour la conversion de devises\n",
    "\n",
    "# 1. Définir l'outil de conversion de devises\n",
    "currency_tool = {\n",
    "    \"name\": \"convert_currency\",\n",
    "    \"description\": \"Convertit un montant d'une devise à une autre\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"amount\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Le montant à convertir\"\n",
    "            },\n",
    "            \"from_currency\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"La devise source (ex: EUR, USD, GBP, JPY)\"\n",
    "            },\n",
    "            \"to_currency\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"La devise cible (ex: EUR, USD, GBP, JPY)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"amount\", \"from_currency\", \"to_currency\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. Implémenter la fonction de conversion de devises\n",
    "def convert_currency(amount, from_currency, to_currency):\n",
    "    \"\"\"\n",
    "    Convertit un montant d'une devise à une autre.\n",
    "    \n",
    "    Paramètres:\n",
    "    - amount: Le montant à convertir\n",
    "    - from_currency: La devise source (EUR, USD, GBP, JPY)\n",
    "    - to_currency: La devise cible (EUR, USD, GBP, JPY)\n",
    "    \n",
    "    Retourne:\n",
    "    - Une chaîne de caractères indiquant le résultat de la conversion\n",
    "    \"\"\"\n",
    "    # À COMPLÉTER: Implémentez la logique de conversion en utilisant les taux suivants:\n",
    "    # 1 EUR = 1.10 USD\n",
    "    # 1 EUR = 0.85 GBP\n",
    "    # 1 EUR = 160 JPY\n",
    "    # 1 USD = 0.91 EUR\n",
    "    # 1 USD = 0.77 GBP\n",
    "    # 1 USD = 145 JPY\n",
    "    # 1 GBP = 1.18 EUR\n",
    "    # 1 GBP = 1.30 USD\n",
    "    # 1 GBP = 188 JPY\n",
    "    # 1 JPY = 0.00625 EUR\n",
    "    # 1 JPY = 0.0069 USD\n",
    "    # 1 JPY = 0.0053 GBP\n",
    "    \n",
    "    # Votre code ici\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Fin de votre code\n",
    "    \n",
    "    return f\"{amount} {from_currency} = {converted_amount:.2f} {to_currency}\"\n",
    "\n",
    "# 3. Tester votre fonction\n",
    "print(\"Tests de conversion de devises:\")\n",
    "# Décommentez ces lignes après avoir implémenté la fonction\n",
    "# print(convert_currency(100, \"EUR\", \"USD\"))\n",
    "# print(convert_currency(50, \"USD\", \"JPY\"))\n",
    "# print(convert_currency(200, \"GBP\", \"EUR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68746dd9-d462-4410-8c13-8ef57dbab5a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Intégration de l'outil de conversion de devises dans le serveur MCP\n",
    "\n",
    "Maintenant que nous avons créé notre outil de conversion de devises, voyons comment l'intégrer dans notre serveur MCP.\n",
    "\n",
    "Dans un serveur MCP réel, nous ajouterions cet outil à la liste des outils disponibles et implémenterions la fonction correspondante dans le gestionnaire de requêtes.\n",
    "\n",
    "Voici comment cela se présenterait dans notre serveur Flask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013816c-dbda-4479-bc14-aca42dc2c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code à ajouter au serveur MCP pour intégrer l'outil de conversion de devises\n",
    "\n",
    "# 1. Ajouter l'outil à la liste TOOLS\n",
    "\"\"\"\n",
    "TOOLS.append({\n",
    "    \"name\": \"convert_currency\",\n",
    "    \"description\": \"Convertit un montant d'une devise à une autre\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"amount\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"Le montant à convertir\"\n",
    "            },\n",
    "            \"from_currency\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"La devise source (ex: EUR, USD, GBP, JPY)\"\n",
    "            },\n",
    "            \"to_currency\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"La devise cible (ex: EUR, USD, GBP, JPY)\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"amount\", \"from_currency\", \"to_currency\"]\n",
    "    }\n",
    "})\n",
    "\"\"\"\n",
    "\n",
    "# 2. Ajouter le gestionnaire dans la fonction run_tool\n",
    "\"\"\"\n",
    "@app.route('/run_tool', methods=['POST'])\n",
    "def run_tool():\n",
    "    data = request.json\n",
    "    tool_name = data.get('name')\n",
    "    parameters = data.get('parameters', {})\n",
    "    \n",
    "    # ... autres outils ...\n",
    "    \n",
    "    elif tool_name == \"convert_currency\":\n",
    "        amount = parameters.get('amount')\n",
    "        from_currency = parameters.get('from_currency')\n",
    "        to_currency = parameters.get('to_currency')\n",
    "        \n",
    "        # Définir les taux de conversion\n",
    "        rates = {\n",
    "            \"EUR\": {\"USD\": 1.10, \"GBP\": 0.85, \"JPY\": 160, \"EUR\": 1.0},\n",
    "            \"USD\": {\"EUR\": 0.91, \"GBP\": 0.77, \"JPY\": 145, \"USD\": 1.0},\n",
    "            \"GBP\": {\"EUR\": 1.18, \"USD\": 1.30, \"JPY\": 188, \"GBP\": 1.0},\n",
    "            \"JPY\": {\"EUR\": 0.00625, \"USD\": 0.0069, \"GBP\": 0.0053, \"JPY\": 1.0}\n",
    "        }\n",
    "        \n",
    "        # Vérifier si les devises sont supportées\n",
    "        if from_currency not in rates or to_currency not in rates:\n",
    "            return jsonify({\n",
    "                \"error\": f\"Devise non supportée. Devises disponibles: {', '.join(rates.keys())}\"\n",
    "            }), 400\n",
    "        \n",
    "        # Effectuer la conversion\n",
    "        conversion_rate = rates[from_currency][to_currency]\n",
    "        converted_amount = amount * conversion_rate\n",
    "        \n",
    "        result = f\"{amount} {from_currency} = {converted_amount:.2f} {to_currency}\"\n",
    "        return jsonify({\"result\": result})\n",
    "    \n",
    "    # ... autres outils ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1e31a-53ff-4138-ba5a-9f3678eaa411",
   "metadata": {},
   "source": [
    "## 8. Intégration avec un modèle de langage réel\n",
    "\n",
    "Maintenant que nous avons créé notre serveur MCP et nos outils, intégrons-les avec un véritable modèle de langage. Nous allons utiliser:\n",
    "- Soit le modèle local LiquidAI/llama.cpp que nous avons configuré dans le notebook 1\n",
    "- Soit l'API OpenAI (avec une clé API partagée)\n",
    "\n",
    "Cette intégration nous permettra de créer un véritable agent IA capable d'utiliser nos outils MCP pour répondre à des questions complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446eae64-8ece-4e79-ba8d-f680cf157861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour l'intégration avec un modèle de langage\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Configuration pour le modèle local (LiquidAI/llama.cpp)\n",
    "from openai import OpenAI\n",
    "\n",
    "# Client pour le modèle local\n",
    "local_client = OpenAI(\n",
    "    base_url=\"http://localhost:8080/v1\",\n",
    "    api_key=\"sk-no-key-required\"  # Clé factice, llama.cpp n'en a pas besoin\n",
    ")\n",
    "\n",
    "# Fonction pour vérifier que le serveur local est en cours d'exécution\n",
    "def check_local_server():\n",
    "    try:\n",
    "        base_url_str = str(local_client.base_url)\n",
    "        \n",
    "        # Supprimer \"/v1\" de l'URL de base pour accéder à \"/models\"\n",
    "        if base_url_str.endswith(\"/v1/\"):\n",
    "            base_url_str = base_url_str[:-3]\n",
    "            \n",
    "        response = requests.get(f\"{base_url_str}/models\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"✅ Connexion au serveur llama.cpp réussie!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Le serveur a répondu avec le code {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Impossible de se connecter au serveur llama.cpp: {str(e)}\")\n",
    "        print(\"Assurez-vous que le serveur est en cours d'exécution sur http://localhost:8080\")\n",
    "        return False\n",
    "\n",
    "# Vérifier si le modèle local est disponible\n",
    "LOCAL_MODEL_AVAILABLE = check_local_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b1cc3-08c4-477c-b6f3-6537d71b165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de la clé API OpenAI\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-votre-clé-api-ici\"  # Remplacez par votre clé API\n",
    "print(\"✅ Clé API OpenAI configurée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b7b0e-521d-4c7d-ae24-dbb6de06edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour OpenAI API\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_AVAILABLE = False\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    try:\n",
    "        # Configurer le client OpenAI\n",
    "        openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        \n",
    "        # Vérifier si la clé API est valide avec un appel minimal\n",
    "        # La méthode list() ne prend pas d'argument limit dans les versions récentes\n",
    "        response = openai_client.models.list()\n",
    "        \n",
    "        OPENAI_AVAILABLE = True\n",
    "        print(\"✅ API OpenAI configurée et disponible\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de la configuration de l'API OpenAI: {str(e)}\")\n",
    "else:\n",
    "    print(\"❌ Clé API OpenAI non trouvée\")\n",
    "\n",
    "# Vérifier qu'au moins une option est disponible\n",
    "if not LOCAL_MODEL_AVAILABLE and not OPENAI_AVAILABLE:\n",
    "    print(\"⚠️ ATTENTION: Aucun modèle de langage n'est disponible. Veuillez configurer soit le modèle local, soit l'API OpenAI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042ce10-7a57-4680-8bff-7594f97f533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe pour notre agent IA utilisant le serveur MCP\n",
    "class MCPAgent:\n",
    "    def __init__(self, use_openai=False):\n",
    "        \"\"\"\n",
    "        Initialise l'agent IA avec le modèle de langage spécifié.\n",
    "        \n",
    "        Args:\n",
    "            use_openai (bool): Si True, utilise l'API OpenAI. Sinon, utilise le modèle local.\n",
    "        \"\"\"\n",
    "        self.use_openai = use_openai\n",
    "        self.conversation_history = []\n",
    "        self.mcp_server_url = \"http://localhost:5000\"\n",
    "        \n",
    "        # Vérifier si l'option choisie est disponible\n",
    "        if use_openai and not OPENAI_AVAILABLE:\n",
    "            raise ValueError(\"L'API OpenAI n'est pas disponible. Veuillez configurer la clé API ou utiliser le modèle local.\")\n",
    "        \n",
    "        if not use_openai and not LOCAL_MODEL_AVAILABLE:\n",
    "            raise ValueError(\"Le modèle local n'est pas disponible. Veuillez démarrer le serveur llama.cpp ou utiliser l'API OpenAI.\")\n",
    "        \n",
    "        # Initialiser le client approprié\n",
    "        if use_openai:\n",
    "            self.client = openai_client\n",
    "            print(\"Agent configuré pour utiliser l'API OpenAI\")\n",
    "        else:\n",
    "            self.client = local_client\n",
    "            print(\"Agent configuré pour utiliser le modèle local (LiquidAI/llama.cpp)\")\n",
    "        \n",
    "        # Vérifier que le serveur MCP est disponible\n",
    "        try:\n",
    "            self.tools = self._get_tools()\n",
    "            print(f\"Serveur MCP détecté avec {len(self.tools)} outils disponibles\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la connexion au serveur MCP: {str(e)}\")\n",
    "            print(\"Assurez-vous que le serveur MCP est en cours d'exécution sur \" + self.mcp_server_url)\n",
    "    \n",
    "    def _get_tools(self):\n",
    "        \"\"\"Récupère la liste des outils disponibles depuis le serveur MCP.\"\"\"\n",
    "        response = requests.get(f\"{self.mcp_server_url}/tools\")\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            raise Exception(f\"Erreur {response.status_code} lors de la récupération des outils\")\n",
    "    \n",
    "    def _run_tool(self, tool_name, parameters):\n",
    "        \"\"\"Exécute un outil via le serveur MCP.\"\"\"\n",
    "        data = {\n",
    "            \"name\": tool_name,\n",
    "            \"parameters\": parameters\n",
    "        }\n",
    "        response = requests.post(f\"{self.mcp_server_url}/run_tool\", json=data)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            raise Exception(f\"Erreur {response.status_code} lors de l'exécution de l'outil {tool_name}\")\n",
    "    \n",
    "    def process_query(self, user_query):\n",
    "        \"\"\"\n",
    "        Traite une requête utilisateur et renvoie une réponse.\n",
    "        \n",
    "        Args:\n",
    "            user_query (str): La requête de l'utilisateur\n",
    "            \n",
    "        Returns:\n",
    "            str: La réponse de l'assistant\n",
    "        \"\"\"\n",
    "        # Ajouter la requête à l'historique\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        \n",
    "        # Récupérer les outils disponibles\n",
    "        try:\n",
    "            tools = self._get_tools()\n",
    "        except Exception as e:\n",
    "            return f\"Erreur lors de la récupération des outils MCP: {str(e)}\"\n",
    "        \n",
    "        # Convertir les outils MCP au format OpenAI\n",
    "        openai_tools = []\n",
    "        for tool in tools:\n",
    "            openai_tools.append({\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool[\"name\"],\n",
    "                    \"description\": tool[\"description\"],\n",
    "                    \"parameters\": tool[\"parameters\"]\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Préparer les messages pour l'API\n",
    "        messages = self.conversation_history.copy()\n",
    "        \n",
    "        try:\n",
    "            # Appeler l'API avec les outils\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\" if self.use_openai else \"local-model\",  # Le nom du modèle n'est pas important pour llama.cpp\n",
    "                messages=messages,\n",
    "                tools=openai_tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "            \n",
    "            # Récupérer le message de réponse\n",
    "            message = response.choices[0].message\n",
    "            \n",
    "            # Vérifier si le modèle veut utiliser un outil\n",
    "            if message.tool_calls:\n",
    "                # Exécuter chaque appel d'outil\n",
    "                for tool_call in message.tool_calls:\n",
    "                    # Extraire les informations de l'outil\n",
    "                    tool_name = tool_call.function.name\n",
    "                    tool_params = json.loads(tool_call.function.arguments)\n",
    "                    \n",
    "                    print(f\"Le modèle utilise l'outil: {tool_name}\")\n",
    "                    \n",
    "                    # Exécuter l'outil via le serveur MCP\n",
    "                    try:\n",
    "                        tool_result = self._run_tool(tool_name, tool_params)\n",
    "                    except Exception as e:\n",
    "                        tool_result = {\"error\": f\"Erreur lors de l'exécution de l'outil: {str(e)}\"}\n",
    "                    \n",
    "                    # Ajouter l'appel d'outil à l'historique\n",
    "                    self.conversation_history.append({\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": None,\n",
    "                        \"tool_calls\": [{\n",
    "                            \"id\": tool_call.id,\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"name\": tool_name,\n",
    "                                \"arguments\": tool_call.function.arguments\n",
    "                            }\n",
    "                        }]\n",
    "                    })\n",
    "                    \n",
    "                    # Ajouter le résultat de l'outil à l'historique\n",
    "                    self.conversation_history.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": json.dumps(tool_result)\n",
    "                    })\n",
    "                \n",
    "                # Obtenir la réponse finale du modèle\n",
    "                final_response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\" if self.use_openai else \"local-model\",\n",
    "                    messages=self.conversation_history\n",
    "                )\n",
    "                \n",
    "                final_content = final_response.choices[0].message.content\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": final_content})\n",
    "                return final_content\n",
    "            else:\n",
    "                # Le modèle a répondu directement sans utiliser d'outil\n",
    "                content = message.content\n",
    "                self.conversation_history.append({\"role\": \"assistant\", \"content\": content})\n",
    "                return content\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Erreur lors de l'appel au modèle: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            \n",
    "            # Gestion de secours pour les modèles locaux qui ne supportent pas complètement l'API OpenAI\n",
    "            if not self.use_openai:\n",
    "                try:\n",
    "                    print(\"Tentative de repli sur l'API de complétion simple...\")\n",
    "                    \n",
    "                    # Construire un prompt qui explique les outils disponibles\n",
    "                    tools_description = json.dumps(tools, ensure_ascii=False, indent=2)\n",
    "                    \n",
    "                    # Construire le prompt avec l'historique de conversation\n",
    "                    conversation_prompt = \"\"\n",
    "                    for message in self.conversation_history:\n",
    "                        role = message[\"role\"]\n",
    "                        content = message.get(\"content\")\n",
    "                        if role == \"user\" and content:\n",
    "                            conversation_prompt += f\"Utilisateur: {content}\\n\\n\"\n",
    "                        elif role == \"assistant\" and content:\n",
    "                            conversation_prompt += f\"Assistant: {content}\\n\\n\"\n",
    "                    \n",
    "                    # Construire le prompt final avec instructions pour utiliser les outils\n",
    "                    system_prompt = f\"\"\"Tu es un assistant IA qui peut utiliser des outils externes.\n",
    "                    Voici les outils disponibles:\n",
    "                    {tools_description}\n",
    "                    \n",
    "                    Pour utiliser un outil, réponds au format suivant:\n",
    "                    ```json\n",
    "                    {{\n",
    "                      \"tool\": \"nom_de_l_outil\",\n",
    "                      \"parameters\": {{\n",
    "                        \"param1\": \"valeur1\",\n",
    "                        \"param2\": \"valeur2\"\n",
    "                      }}\n",
    "                    }}\n",
    "                    ```\n",
    "                    Si tu n'as pas besoin d'utiliser d'outil, réponds normalement. \"\"\"\n",
    "\n",
    "                    full_prompt = f\"{system_prompt}\\n\\n{conversation_prompt}Assistant: \"\n",
    "                \n",
    "                    # Appeler l'API de complétion\n",
    "                    response = requests.post(\n",
    "                        \"http://localhost:8080/completion\",\n",
    "                        json={\n",
    "                            \"prompt\": full_prompt,\n",
    "                            \"max_tokens\": 1000,\n",
    "                            \"temperature\": 0.7,\n",
    "                            \"stop\": [\"\\nUtilisateur:\", \"\\n\\nUtilisateur:\"]\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "                    if response.status_code != 200:\n",
    "                        return f\"Erreur {response.status_code} lors de l'appel au modèle local: {response.text}\"\n",
    "                    \n",
    "                    model_response = response.json().get(\"content\", \"\")\n",
    "                    \n",
    "                    # Analyser la réponse pour détecter un appel d'outil\n",
    "                    import re\n",
    "                    tool_call_match = re.search(r'```json\\s*({.*?})\\s*```', model_response, re.DOTALL)\n",
    "                    \n",
    "                    if tool_call_match:\n",
    "                        # Extraire et analyser l'appel d'outil\n",
    "                        try:\n",
    "                            tool_call = json.loads(tool_call_match.group(1))\n",
    "                            tool_name = tool_call.get(\"tool\")\n",
    "                            tool_params = tool_call.get(\"parameters\", {})\n",
    "                            \n",
    "                            print(f\"Le modèle utilise l'outil: {tool_name}\")\n",
    "                            \n",
    "                            # Exécuter l'outil via le serveur MCP\n",
    "                            try:\n",
    "                                tool_result = self._run_tool(tool_name, tool_params)\n",
    "                                print(f\"Résultat de l'outil: {json.dumps(tool_result)}\")\n",
    "                                \n",
    "                                # Construire un nouveau prompt avec le résultat de l'outil\n",
    "                                tool_prompt = f\"{full_prompt}Je vais utiliser l'outil {tool_name}.\\n\\nRésultat de l'outil: {json.dumps(tool_result, ensure_ascii=False)}\\n\\nMaintenant, je vais répondre à la question: \"\n",
    "                                \n",
    "                                # Appeler à nouveau le modèle avec le résultat de l'outil\n",
    "                                final_response = requests.post(\n",
    "                                    \"http://localhost:8080/completion\",\n",
    "                                    json={\n",
    "                                        \"prompt\": tool_prompt,\n",
    "                                        \"max_tokens\": 1000,\n",
    "                                        \"temperature\": 0.7,\n",
    "                                        \"stop\": [\"\\nUtilisateur:\", \"\\n\\nUtilisateur:\"]\n",
    "                                    }\n",
    "                                )\n",
    "                                \n",
    "                                if final_response.status_code == 200:\n",
    "                                    final_content = final_response.json().get(\"content\", \"\")\n",
    "                                    self.conversation_history.append({\"role\": \"assistant\", \"content\": final_content})\n",
    "                                    return final_content\n",
    "                            except Exception as tool_error:\n",
    "                                return f\"Erreur lors de l'exécution de l'outil {tool_name}: {str(tool_error)}\"\n",
    "                        except json.JSONDecodeError:\n",
    "                            pass\n",
    "                    \n",
    "                    # Si aucun appel d'outil n'est détecté ou s'il y a une erreur, retourner la réponse directe\n",
    "                    self.conversation_history.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "                    return model_response\n",
    "                    \n",
    "                except Exception as fallback_error:\n",
    "                    return f\"{error_msg}\\n\\nErreur de repli: {str(fallback_error)}\"\n",
    "            \n",
    "            return error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7e2ec-9815-47ba-abdc-bfe6850982f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester notre agent avec quelques requêtes\n",
    "\n",
    "# Choisir le modèle à utiliser\n",
    "USE_OPENAI = False  # Mettre à True pour utiliser OpenAI, False pour le modèle local\n",
    "\n",
    "# Créer l'agent\n",
    "try:\n",
    "    agent = MCPAgent(use_openai=USE_OPENAI)\n",
    "    \n",
    "    # Fonction pour afficher les conversations de manière plus lisible\n",
    "    from IPython.display import HTML, display\n",
    "    \n",
    "    def display_conversation(query, response):\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin-bottom: 10px;\">\n",
    "            <strong>Vous:</strong> {query}\n",
    "        </div>\n",
    "        <div style=\"background-color: #e8f4f8; padding: 10px; border-radius: 5px; margin-bottom: 20px;\">\n",
    "            <strong>Assistant:</strong> {response}\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    \n",
    "    # Test 1: Question simple sur la date\n",
    "    query1 = \"Quelle est la date et l'heure actuelles?\"\n",
    "    print(\"Traitement de la requête: \" + query1)\n",
    "    response1 = agent.process_query(query1)\n",
    "    display_conversation(query1, response1)\n",
    "    \n",
    "    # Test 2: Calcul mathématique\n",
    "    query2 = \"Peux-tu calculer 25 * 16 + 42?\"\n",
    "    print(\"Traitement de la requête: \" + query2)\n",
    "    response2 = agent.process_query(query2)\n",
    "    display_conversation(query2, response2)\n",
    "\n",
    "    # Test 3: Conversion de devises (notre nouvel outil)\n",
    "    query3 = \"Quel temps fait il sur Paris?\"\n",
    "    print(\"Traitement de la requête: \" + query3)\n",
    "    response3 = agent.process_query(query3)\n",
    "    display_conversation(query3, response3)\n",
    "    \n",
    "    # Test 4: Conversion de devises (notre nouvel outil)\n",
    "    query4 = \"Combien valent 100 euros en dollars américains?\"\n",
    "    print(\"Traitement de la requête: \" + query4)\n",
    "    response4 = agent.process_query(query4)\n",
    "    display_conversation(query4, response4)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'initialisation ou de l'utilisation de l'agent: {str(e)}\")\n",
    "    print(\"\\nVeuillez vérifier que:\")\n",
    "    print(\"1. Le serveur du modèle local est en cours d'exécution (si vous utilisez le modèle local)\")\n",
    "    print(\"2. La clé API OpenAI est correctement configurée (si vous utilisez OpenAI)\")\n",
    "    print(\"3. Les outils MCP sont correctement définis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee80014-0b4d-4e6a-a36b-46d23e75359d",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons:\n",
    "\n",
    "1. **Abordé les concepts fondamentaux de l'IA agentique**\n",
    "   - Définition et caractéristiques d'un agent IA\n",
    "   - Architecture et composants d'un agent IA\n",
    "\n",
    "2. **Exploré le Model Context Protocol (MCP)**\n",
    "   - Structure et fonctionnement du MCP\n",
    "   - Avantages de l'utilisation du MCP pour les agents IA\n",
    "\n",
    "3. **Créé un serveur MCP simple**\n",
    "   - Implémentation d'un serveur MCP avec Flask\n",
    "   - Définition d'outils MCP pour différentes fonctionnalités\n",
    "\n",
    "4. **Développé et intégré un nouvel outil MCP**\n",
    "   - Création d'un outil de conversion de devises\n",
    "   - Intégration de l'outil dans l'environnement MCP\n",
    "\n",
    "5. **Intégré notre serveur MCP avec un modèle de langage réel**\n",
    "   - Utilisation du modèle local LiquidAI/llama.cpp\n",
    "   - Option d'utilisation de l'API OpenAI\n",
    "   - Création d'un agent IA complet capable d'utiliser des outils\n",
    "\n",
    "Cette approche nous permet de créer des agents IA puissants qui peuvent interagir avec le monde extérieur via des outils, tout en gardant le contrôle sur les capacités et les limites de ces agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c889b-5be8-4a6f-ae67-f7abb208c0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
